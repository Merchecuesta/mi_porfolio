
# ===============================================
# STREAMLIT APP CON FONDO, SIDEBAR CUSTOM E √çNDICE
# ===============================================

import streamlit as st
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns
import plotly.graph_objects as go
import joblib
from phik import phik_matrix
from phik.report import plot_correlation_matrix
from PIL import Image
from catboost import CatBoostClassifier
from sklearn.base import BaseEstimator, TransformerMixin
from streamlit_option_menu import option_menu
import base64
import streamlit as st
from streamlit_option_menu import option_menu


st.markdown(
    """
    <style>
    /* FUENTE GENERAL */
    html, body, [class*="css"] {
        font-family: 'Candara', 'Candara Light', Calibri, 'Segoe UI', sans-serif !important;
    }

    h1, h2, h3, h4, h5, h6, p, div, span {
        font-family: 'Candara', 'Candara Light', Calibri, 'Segoe UI', sans-serif !important;
    }

    /* FONDO EN TODA LA P√ÅGINA (incluyendo fuera del cuerpo) */
    body {
        background-image: linear-gradient(rgba(255,255,255,0.9), rgba(255,255,255,0.9)),
                          url("https://raw.githubusercontent.com/Merchecuesta/ONLINE_DS_THEBRIDGE_MERCHECUESTA/main/fondo.jpg");
        background-size: cover;
        background-position: center;
        background-attachment: fixed;
    }

    /* OPCIONAL: fondo blanco semi-transparente para el contenido principal */
    .main .block-container {
        background-color: rgba(255, 255, 255, 0.85);
        padding: 2rem;
        border-radius: 12px;
    }
    </style>
    """,
    unsafe_allow_html=True
)


# Men√∫ + √≠ndice combinado
with st.sidebar:
    selected = option_menu(
        menu_title="√çndice",
        options=[
            "Objetivo",
            "Datos",
            "M√©tricas",
            "Modelos",
            "Comparaci√≥n entre Modelos",
            "Coste-Beneficio",
            "Predictor de Churn"
        ],
        icons=[
            "info-circle", "calculator", "bar-chart-line", "gear", "graph-up", "currency-dollar", "pie-chart"
        ],
        menu_icon="cast",
        default_index=0,
        orientation="vertical",
        styles={
            "container": {"padding": "5px", "background-color": "#f0f2f6"},
            "icon": {"color": "#004d99", "font-size": "20px"},
            "nav-link": {
                "font-size": "18px",
                "text-align": "left",
                "margin": "5px",
                "--hover-color": "#99ccff",
                "color": "#004d99",
                "border-radius": "10px",
            },
            "nav-link-selected": {
                "background-color": "#004d99",
                "color": "white",
            },
        }
    )
df = pd.read_csv('ML/data/Telco_churn.csv')


# =========================
# FUNCIONES
# =========================

# Matriz de confusion
def mostrar_matriz_confusion(tn, fp, fn, tp, modelo):
    data = {
        "Predicci√≥n Negativa": [f"TN: {tn}", f"FN: {fn}"],
        "Predicci√≥n Positiva": [f"FP: {fp}", f"TP: {tp}"]
    }
    df_cm = pd.DataFrame(data, index=["Cliente NO dado de baja", "Cliente S√ç dado de baja"])
    
    st.subheader(f"Matriz de Confusi√≥n - {modelo}")
    st.table(df_cm)


# Metricas de negocio

def mostrar_metricas_negocio(precision0, recall0, f1_0, support0, 
                              precision1, recall1, f1_1, support1, 
                              accuracy, auc_roc):
    st.subheader("M√©tricas de negocio")
    
    df_metrics = pd.DataFrame({
        "Cliente NO dado de baja": [precision0, recall0, f1_0, support0],
        "Cliente S√ç dado de baja": [precision1, recall1, f1_1, support1]
    }, index=["Precisi√≥n", "Recall", "F1-score", "N¬∫ de casos"])
    
    st.table(df_metrics)
    st.write(f"**Exactitud global (Accuracy):** {accuracy}")
    st.write(f"**AUC-ROC:** {auc_roc}")


# Mostrar contenido seg√∫n men√∫
st.title(selected)

if selected == "Objetivo":
    st.subheader("Predicci√≥n de Abandono de Clientes en empresa de Telecomunicaciones")
    st.markdown("""
    El prop√≥sito principal de este proyecto es **anticipar el abandono de clientes (churn)** en una empresa del sector de telecomunicaciones.  
    A trav√©s del an√°lisis de datos hist√≥ricos sobre el comportamiento, perfil y contrataci√≥n de servicios de los usuarios, buscamos:

    - **Identificar patrones y factores clave** asociados al abandono.
    - **Predecir con precisi√≥n** qu√© clientes tienen mayor probabilidad de dejar la compa√±√≠a.
    - **Segmentar la base de clientes** seg√∫n su riesgo de churn.
    - **Dise√±ar estrategias de retenci√≥n personalizadas y efectivas**, enfocadas en reducir la p√©rdida de clientes y optimizar la rentabilidad.

    Este enfoque permitir√° a la empresa **tomar decisiones proactivas** basadas en datos, mejorando tanto la fidelizaci√≥n como la eficiencia de las campa√±as de marketing.
    """)
    
elif selected == "Datos":
    st.markdown("""
    En la reuni√≥n inicial con el cliente, se analiz√≥ el conjunto de datos entregado, que contiene informaci√≥n detallada sobre **7,043** observaciones.  
    
    Los datos incluyen tanto variables demogr√°ficas como de los servicios contratados.
    
    Contamos con las siguientes columnas principales:

    | Columna           | Descripci√≥n                                                                                 |
    |-------------------|---------------------------------------------------------------------------------------------|
    | customerID      | Identificador √∫nico de cada cliente                                                        |
    | gender          | G√©nero del cliente (Male / Female)                                                         |
    | SeniorCitizen   | Indica si el cliente es mayor de 65 a√±os (1 = s√≠, 0 = no)                                      |
    | Partner         | Indica si el cliente tiene pareja (Yes / No)                                               |
    | Dependents      | Indica si el cliente tiene personas dependientes a su cargo (Yes / No)                     |
    | tenure          | N√∫mero de meses que el cliente lleva con la empresa                                       |
    | PhoneService    | Indica si el cliente tiene servicio telef√≥nico (Yes / No)                                 |
    | MultipleLines   | Indica si el cliente tiene m√∫ltiples l√≠neas telef√≥nicas (Yes / No / No phone service)      |
    | InternetService | Tipo de servicio de internet contratado (DSL / Fiber optic / No)                          |
    | OnlineSecurity  | Servicio de seguridad online adicional (Yes / No / No internet service)                   |
    | OnlineBackup    | Servicio de respaldo online (Yes / No / No internet service)                              |
    | DeviceProtection| Plan de protecci√≥n para dispositivos (Yes / No / No internet service)                     |
    | TechSupport     | Soporte t√©cnico adicional (Yes / No / No internet service)                                |
    | StreamingTV     | Uso de servicio de streaming de TV (Yes / No / No internet service)                       |
    | StreamingMovies | Uso de servicio de streaming de pel√≠culas (Yes / No / No internet service)                |
    | Contract        | Tipo de contrato (Month-to-month / One year / Two year)                                   |
    | PaperlessBilling| Uso de facturaci√≥n sin papel (Yes / No)                                                   |
    | PaymentMethod   | M√©todo de pago (Bank transfer / Credit card / Electronic check / Mailed check)            |
    | MonthlyCharges  | Cargo mensual que paga el cliente                                                         |
    | TotalCharges    | Total de cargos acumulados (puede tener valores faltantes si tenure es cero)                 |
    | Churn           | Variable objetivo: indica si el cliente abandon√≥ la empresa (Yes / No)                    |
    
    Determinamos que el n√∫mero de datos aportado es suficiente para entrenar a un modelo y preveemos que al tener el 'Churn' (lo que el cliente desea predecir) podemos inclinarnos por un tipo de modelo supervisado.
    """)

    st.subheader("Proporci√≥n de Clientes que Abandonan vs. Retienen")

    st.markdown("""
    Para comprender mejor el reto de predicci√≥n, es fundamental conocer c√≥mo se distribuyen las clases seg√∫n la variable objetivo (Churn).  
    Analizar esta proporci√≥n nos permite identificar si el modelo deber√° enfrentarse a un **problema de clases balanceadas** o si, por el contrario, se trata de una **clase minoritaria**, lo que implicar√≠a un escenario de **desbalance de clases**.  
    Esta informaci√≥n es clave para definir la estrategia de modelado y las m√©tricas de evaluaci√≥n m√°s adecuadas.
    """)

    # C√°lculo de conteos
    counts = df['Churn'].value_counts()
    labels = ['No', 'S√≠']
    values = [counts['No'], counts['Yes']]
    colors = ['mediumseagreen', 'indianred']

    # Crear gr√°fico de pastel
    fig = go.Figure(data=[go.Pie(
        labels=labels,
        values=values,
        marker=dict(colors=colors),
        textinfo='label+percent',
        textfont=dict(size=16)
    )])

    fig.update_layout(
        title_text="Proporci√≥n de Clientes que Abandonan vs. Retienen",
        margin=dict(t=40, b=0, l=0, r=0)
    )

    st.plotly_chart(fig, use_container_width=True)
    
    st.subheader("Correlaci√≥n y Multicolinealidad entre las variables")
    st.subheader("Heatmap de Correlaci√≥n Phi_k")
    img = Image.open('phik_heatmap.png')
    st.image(img, use_container_width=True)

    st.markdown("""
    Como se puede apreciar en este mapa de calor, la mayor√≠a de las variables son categ√≥ricas y muestran distintos grados de correlaci√≥n entre ellas.  
    Esto significa que algunos atributos est√°n relacionados o tienden a comportarse de manera similar, lo que puede influir en la construcci√≥n del modelo y en la interpretaci√≥n de los resultados. 
    De manera contraria, vemos que hay algunos que apenas guardan relaci√≥n con otros.  
    
    Entender estas relaciones es fundamental para seleccionar las variables m√°s relevantes y evitar redundancias que puedan afectar la precisi√≥n del modelo.
    """)

elif selected == "M√©tricas":
    st.header("M√©tricas de Evaluaci√≥n del Modelo")
    st.markdown("""
    Se propusieron las siguientes m√©tricas para evaluar el desempe√±o del modelo y su impacto en negocio:

    | M√©trica                 | ¬øQu√© mide?                                                         | ¬øPor qu√© es √∫til para su negocio?                           |
    |-------------------------|------------------------------------------------------------------|------------------------------------------------------------|
    | **Recall (Sensibilidad)** | De todos los clientes que se van, ¬øcu√°ntos detectamos?           | Detecta la fuga real. Prioridad alta para retenci√≥n         |
    | **Precision**           | De los clientes predichos como churn, ¬øcu√°ntos realmente se van? | Evita costes innecesarios y molestias a clientes            |
    | **F1 Score**            | Balance entre precision y recall                                 | Equilibrio para detectar churn sin alarmar en exceso        |
    | **Matriz de confusi√≥n** | Verdaderos/falsos positivos y negativos                          | Interpretaci√≥n clara de errores y aciertos                   |
    | **Accuracy**            | Proporci√≥n de predicciones correctas en total                    | Medida general de efectividad. Poco √∫til en clases desbalanceadas                                |
    | **ROC AUC Score**       | Capacidad del modelo para distinguir las clases                  | M√©trica global, aunque menos intuitiva para negocio          |
    """)

    st.markdown("""
    El cliente da m√°xima importancia al **Recall** para asegurarse de detectar la mayor cantidad posible de clientes que podr√≠an abandonar la compa√±√≠a.  
    
    Sin embargo, tambi√©n se buscar√° un buen equilibrio entre precisi√≥n y recall para seleccionar el modelo m√°s adecuado, evitando falsas alarmas innecesarias y optimizando la efectividad de las acciones de retenci√≥n.
    
    Finalmente se decide que el modelo con mejor **ROC** y buen **Recall** ser√° el elegido
    """)



elif selected == "Modelos":
    st.header("An√°lisis de Modelos de Clasificaci√≥n")

    # ---------------------------
    # MODELO 1: Regresi√≥n Log√≠stica
    # ---------------------------
    with st.expander("Regresi√≥n Log√≠stica"):
        st.header("""
        **Interpretaci√≥n del modelo:**

        La Regresi√≥n Log√≠stica logra detectar bastantes clientes que se dan de baja (recall de 0.78 en la clase positiva),
        aunque comete muchos falsos positivos (clientes que no se dan de baja pero el modelo dice que s√≠).

        La precisi√≥n para los que se dan de baja es baja (0.47), lo que indica que muchos de los que el modelo predice como baja no lo son realmente.

        El AUC-ROC de 0.816 sugiere que el modelo tiene buena capacidad discriminativa general.
        """)

        mostrar_matriz_confusion(tn=1057, fp=495, fn=123, tp=438, modelo="Regresi√≥n Log√≠stica")

        mostrar_metricas_negocio(
            precision0=0.90, recall0=0.68, f1_0=0.77, support0=1552,
            precision1=0.47, recall1=0.78, f1_1=0.59, support1=561,
            accuracy=0.71, auc_roc=0.816
        )

    # ---------------------------
    # MODELO 2: Random Forest
    # ---------------------------
    with st.expander("Random Forest"):
        st.header("""
        **Interpretaci√≥n del modelo:**

        Random Forest mejora el equilibrio entre precisi√≥n y recall. Detecta muchos clientes que se dan de baja (recall de 0.76) 
        y tambi√©n reduce la cantidad de falsos positivos respecto al modelo anterior.

        Su precisi√≥n en la clase positiva mejora hasta 0.55 y tiene un mejor `f1-score`.

        AUC-ROC sube a 0.842, indicando una mejor discriminaci√≥n general.
        """)

        mostrar_matriz_confusion(tn=1201, fp=351, fn=135, tp=426, modelo="Random Forest")

        mostrar_metricas_negocio(
            precision0=0.90, recall0=0.77, f1_0=0.83, support0=1552,
            precision1=0.55, recall1=0.76, f1_1=0.64, support1=561,
            accuracy=0.77, auc_roc=0.842
        )

    # ---------------------------
    # MODELO 3: CatBoost
    # ---------------------------
    with st.expander("CatBoost"):
        st.header("""
        **Interpretaci√≥n del modelo:**

        CatBoost mantiene un recall alto en clientes que se dan de baja (0.79), similar a los anteriores, pero consigue mejor equilibrio.

        Aunque su precisi√≥n en la clase positiva es algo baja (0.52), destaca por su rendimiento estable.

        El AUC-ROC es el mejor de los tres (0.852), lo que lo convierte en un modelo muy competitivo para detectar bajas.
        """)

        mostrar_matriz_confusion(tn=757, fp=278, fn=78, tp=296, modelo="CatBoost")

        mostrar_metricas_negocio(
            precision0=0.91, recall0=0.73, f1_0=0.81, support0=1035,
            precision1=0.52, recall1=0.79, f1_1=0.62, support1=374,
            accuracy=0.75, auc_roc=0.852
        )

    # ---------------------------
    # MODELO 4: LightGBM
    # ---------------------------
    with st.expander("LightGBM"):
        st.header("""
        **Interpretaci√≥n del modelo:**

        LightGBM ofrece un excelente equilibrio entre precisi√≥n y recall, logrando detectar correctamente a la mayor√≠a de clientes que se dan de baja (recall de 0.82) y manteniendo una precisi√≥n aceptable.

        Tiene un `AUC-ROC` de **0.834**, indicando una muy buena capacidad de clasificaci√≥n.
        """)

        mostrar_matriz_confusion(tn=717, fp=316, fn=69, tp=305, modelo="LightGBM")

        mostrar_metricas_negocio(
            precision0=0.9122, recall0=0.6941, f1_0=0.7883, support0=1033,
            precision1=0.4911, recall1=0.8155, f1_1=0.6131, support1=374,
            accuracy=0.7264, auc_roc=0.8338
        )

    # ---------------------------
    # MODELO 5: XGBoost
    # ---------------------------
    with st.expander("XGBoost"):
        st.header("""
        **Interpretaci√≥n del modelo:**

        XGBoost destaca por su robustez. Con recall de **0.82** en la clase de baja y una precisi√≥n razonable de **0.49**, logra un `AUC-ROC` de **0.841**, el segundo m√°s alto de todos los modelos.

        Es una opci√≥n competitiva para predecir bajas con buena precisi√≥n global.
        """)

        mostrar_matriz_confusion(tn=1075, fp=477, fn=101, tp=460, modelo="XGBoost")

        mostrar_metricas_negocio(
            precision0=0.91, recall0=0.69, f1_0=0.79, support0=1552,
            precision1=0.49, recall1=0.82, f1_1=0.61, support1=561,
            accuracy=0.73, auc_roc=0.841
        )

    # ---------------------------
    # MODELO 6: K-Means (No Supervisado)
    # ---------------------------
    with st.expander("K-Means (No Supervisado)"):
        st.header("""
        **Interpretaci√≥n del modelo:**

        Aunque K-Means no usa la variable objetivo (Churn) para entrenar, los clusters formados muestran diferencias interesantes.

        - El **Cluster 0** tiene un `churn` del **31.9%**, mientras que el **Cluster 1** solo del **7.4%**.
        - El modelo segmenta a los clientes en perfiles: modernos/digitales vs. tradicionales.

        **Matriz de confusi√≥n entre cluster y churn real:**
        """)

        mostrar_matriz_confusion(tn=3756, fp=1407, fn=1756, tp=113, modelo="K-Means")

        st.markdown("""
        **Conclusiones clave:**

        - **Cluster 0** ‚Üí Clientes modernos, pagan m√°s, usan streaming y facturaci√≥n electr√≥nica ‚Üí **alto riesgo de baja**.
        - **Cluster 1** ‚Üí Clientes tradicionales, contratos largos, sin servicios extra ‚Üí **bajo riesgo de baja**.

         **Estrategia**:
        - Retener a los clientes del Cluster 0 (valiosos pero con riesgo).
        - Mantener satisfechos a los del Cluster 1 (estables, aunque menos rentables).
        """)


elif selected == "Comparaci√≥n entre Modelos":
    st.subheader("Comparativa de M√©tricas entre Modelos")

    import pandas as pd

    metricas_df = pd.DataFrame({
        "Modelo": [
            "Regresi√≥n Log√≠stica",
            "Random Forest",
            "CatBoost",
            "LightGBM",
            "XGBoost",
            "K-Means (No Supervisado)"
        ],
        "Accuracy": [0.71, 0.77, 0.75, 0.7264, 0.73, 0.55],
        "Precision": [0.47, 0.55, 0.52, 0.4911, 0.49, 0.07],
        "Recall": [0.78, 0.76, 0.79, 0.8155, 0.82, 0.06],
        "F1-Score": [0.59, 0.64, 0.62, 0.6131, 0.61, 0.07],
        "AUC-ROC": [0.816, 0.842, 0.852, 0.8338, 0.841, None]
    })

    st.dataframe(metricas_df.style.format(precision=3), use_container_width=True)

    st.markdown("""
    ### Conclusiones Finales

    - **CatBoost** se posiciona como el modelo **m√°s equilibrado y robusto**: logra el **mayor AUC-ROC (0.852)**, lo que indica la **mejor capacidad para discriminar entre clientes que abandonan y los que no**, y mantiene un **recall muy competitivo (0.79)**. Esto lo convierte en una opci√≥n especialmente confiable para identificar clientes en riesgo sin comprometer la calidad general del modelo.

    - **XGBoost** destaca por tener el **mayor recall (0.82)**, es decir, detecta ligeramente m√°s clientes que se dar√°n de baja, aunque con un **AUC-ROC ligeramente inferior (0.841)**, lo que sugiere un menor equilibrio global.

    - **LightGBM** tambi√©n muestra un rendimiento destacable, con un **recall de 0.8155** y **AUC-ROC de 0.834**, lo que lo convierte en una alternativa v√°lida si se prioriza velocidad y eficiencia computacional.

    - **K-Means**, al ser un algoritmo no supervisado, **no es √∫til directamente para predecir el churn**, pero **aporta valor en la segmentaci√≥n** de clientes por perfiles de riesgo, lo que puede enriquecer estrategias de retenci√≥n.

    - Modelos como **Random Forest** y **Regresi√≥n Log√≠stica** quedan rezagados en t√©rminos de recall y AUC-ROC, aunque podr√≠an ser √∫tiles en entornos donde la interpretabilidad del modelo sea clave.

    ---

    ### **Recomendaci√≥n Final para decisi√≥n de Negocio**

    Si el objetivo principal es **maximizar la detecci√≥n de clientes en riesgo (recall)** manteniendo un **alto nivel de discriminaci√≥n general** y **consistencia en las m√©tricas clave**:
    
    **CatBoost es la mejor elecci√≥n**  
    Ofrece **la mayor capacidad predictiva global (AUC-ROC = 0.852)**, con un **recall competitivo (0.79)** y una **excelente estabilidad en m√©tricas**. Es especialmente recomendable si se busca un modelo s√≥lido y balanceado para producci√≥n.
    
    **XGBoost**, si bien obtiene un recall ligeramente mayor (0.82), presenta una **p√©rdida de equilibrio global**, por lo que es recomendable **solo si el negocio prioriza exclusivamente la sensibilidad** por encima de todo lo dem√°s.
    
    **LightGBM** es una alternativa eficiente, muy √∫til en entornos donde el **tiempo de entrenamiento o escalabilidad** sea un factor clave, aunque ligeramente por debajo de CatBoost en t√©rminos de rendimiento.

    ---

    ### **Respuesta de Negocio**
    
    La elecci√≥n recomendada es: **CatBoost**.

    **Ventajas clave**:

    -  **Menos falsos positivos**: se reducen los errores al identificar clientes fieles como si fueran a darse de baja.
    -  **Campa√±as de retenci√≥n m√°s eficientes**: se enfocan en quienes realmente est√°n en riesgo, optimizando recursos.
    -  **Mejor experiencia de cliente**: se evitan acciones innecesarias sobre clientes satisfechos, lo que mejora la relaci√≥n con la marca.
    """)

elif selected == "Coste-Beneficio":
    st.header("Simulaci√≥n Coste/Beneficio campa√±as Marketing ajustadas al modelo")

    st.markdown("""
    Bas√°ndonos en la informaci√≥n proporcionada por el departamento de Marketing, llevamos a cabo una simulaci√≥n econ√≥mica con el objetivo de evaluar el coste/beneficio de las campa√±as de marketing, usando nuestro modelo:
    """)

    # Tabla resumen de par√°metros
    parametros = pd.DataFrame({
        "Par√°metro": [
            "Ingreso medio mensual", "Coste de contacto por cliente", "Tiempo adicional retenido",
            "Porcentaje √©xito retenci√≥n"
        ],
        "Valor": ["70 EUR", "10 EUR", "4 meses", "30 %"],
        "Descripci√≥n": [
            "Mediana de MonthlyCharges", "Llamada, mensaje u oferta", "Estimaci√≥n media",
            "Clientes que deciden quedarse tras contacto"
        ]
    })
    st.table(parametros)

    opcion_campana = st.radio("Campa√±as:", ["Retenci√≥n Si/No", "Segmentaci√≥n", "Comparativa entre ellas"])

    if opcion_campana == "Retenci√≥n Si/No":
        st.subheader("Campa√±a de retenci√≥n centrada solo en si el cliente es churn o no")
        st.subheader("**Resultados sobre test set (1.409 clientes):**")
        res_test = pd.DataFrame({
            "Concepto": [
                "Clientes reales con churn", "Recall del modelo", "Precisi√≥n del modelo",
                "Clientes contactados por campa√±a", "Verdaderos positivos (churn real)", "Falsos positivos (no churn)"
            ],
            "Valor": [374, "79%", "52%", 574, 296, 278]
        })
        st.table(res_test)

        # C√°lculo econ√≥mico
        st.markdown("**C√°lculo econ√≥mico:**")
        economico = pd.DataFrame({
            "Concepto": [
                "Coste total campa√±a", "Clientes retenidos", "Ingresos salvados",
                "Beneficio neto", "ROI"
            ],
            "Valor": [
                "5.740 EUR", "83", "23.240 EUR", "17.500 EUR", "3.05"
            ],
            "C√°lculo": [
                "574 clientes x 10 EUR", "296 x 30 %", "83 clientes x 280 EUR", "23.240 - 5.740 EUR", "17.500 / 5.740"
            ]
        })
        st.table(economico)

        st.subheader("Visualizaci√≥n Coste vs Ingresos Salvados Campa√±a Si/No")

        df_grafico = pd.DataFrame({
            "Concepto": ["Coste de la Campa√±a", "Ingresos Salvados"],
            "EUR": [5740, 23240]
        })
        palette = ["#e74c3c", "#27ae60"]

        fig1, ax1 = plt.subplots(figsize=(4, 3))
        sns.barplot(data=df_grafico, x="Concepto", y="EUR", palette=palette, ax=ax1)

        ax1.set_ylabel("EUR", fontsize=8)
        ax1.set_title("Coste de campa√±a vs Ingresos salvados", fontsize=9)
        ax1.tick_params(axis='x', labelsize=7)
        ax1.tick_params(axis='y', labelsize=7)

        # Anotaciones dentro de las barras
        for p in ax1.patches:
            altura = p.get_height()
            ax1.text(
                p.get_x() + p.get_width() / 2,
                altura / 2,
                f'{altura:,.2f} EUR',
                ha='center',
                va='center',
                color='black',
                fontsize=7,
                fontweight='bold'
            )

        st.pyplot(fig1)

    elif opcion_campana == "Segmentaci√≥n":
        st.subheader("Campa√±a de retenci√≥n basada en segmentaci√≥n por probabilidad de churn")
        st.markdown("""
        Proposici√≥n segmentaci√≥n clientes seg√∫n la probabilidad de churn para adaptar el gasto en campa√±as seg√∫n riesgo.
        """)

        # Tabla de rangos
        rango_prob = pd.DataFrame({
            "Rango probabilidad": ["0.85 - 1.00", "0.65 - 0.84", "0.40 - 0.64"],
            "Etiqueta de riesgo": ["Alto riesgo", "Riesgo moderado-alto", "Riesgo medio"],
            "Interpretaci√≥n": [
                "Cliente muy probable de abandonar",
                "Requiere atenci√≥n inmediata",
                "Posible abandono si no se act√∫a"
            ]
        })
        st.markdown("**Rangos y etiquetas:**")
        st.table(rango_prob)

        # Tabla de costes por riesgo
        st.markdown("**Costes por segmento:**")
        costes_segmento = pd.DataFrame({
            "Nivel riesgo": ["Alto riesgo", "Moderado-alto", "Riesgo medio", "Total"],
            "Clientes": [123, 288, 286, 697],
            "Coste medio (EUR)": [10.47, 5.46, 1.82, ""],
            "Coste total (EUR)": [1287.81, 1572.48, 520.52, 3380.81]
        })
        st.table(costes_segmento)

        # Tabla ingresos salvados
        st.markdown("**Ingresos salvados y beneficios:**")
        beneficios_segmento = pd.DataFrame({
            "Nivel riesgo": ["Alto riesgo", "Moderado-alto", "Riesgo medio", "Total"],
            "Clientes retenidos": [37, 86, 86, 209],
            "Ingresos salvados (EUR)": [10360, 24080, 24080, 58520]
        })
        st.table(beneficios_segmento)

        # Tabla resumen ROI
        st.markdown("**Resumen:**")
        resumen_seg = pd.DataFrame({
            "Concepto": ["Coste total campa√±a", "Ingresos salvados", "Beneficio neto", "ROI"],
            "Valor (EUR)": ["3.380,81", "58.520", "55.139,19", "16,3"]
        })
        st.table(resumen_seg)

        # üéØ Gr√°fico comparaci√≥n ingresos por riesgo
        st.header("Visualizaci√≥n Ingresos vs Coste de Campa√±a Segmentaci√≥n")

        coste_total = 1287.81 + 1572.48 + 520.52  # = 3380.81 EUR
        ingresos_totales = 10360 + 24080 + 24080  # = 58520 EUR

        labels = ["Coste Total Campa√±a", "Ingresos Salvados"]
        valores = [coste_total, ingresos_totales]
        colores = ['#e74c3c', '#27ae60']  # rojo para coste, verde para ingresos

        fig, ax = plt.subplots(figsize=(4, 3))
        bars = ax.bar(labels, valores, color=colores)

        ax.set_ylabel("EUR", fontsize=8)
        ax.set_title("Coste Campa√±a vs Ingresos Salvados Segmentaci√≥n", fontsize=9)
        ax.tick_params(axis='x', labelsize=7)
        ax.tick_params(axis='y', labelsize=7)

        # Anotaciones dentro de las barras
        for bar in bars:
            altura = bar.get_height()
            ax.text(
                bar.get_x() + bar.get_width() / 2,
                altura / 2,
                f'{altura:,.2f} EUR',
                ha='center',
                va='center',
                color='black',
                fontsize=7,
                fontweight='bold'
            )

        st.pyplot(fig)

    elif opcion_campana == "Comparativa entre ellas":
        st.subheader("Comparaci√≥n visual de las dos campa√±as de publicidad")

        # Datos
        labels = ['Coste Campa√±a', 'Ingresos Salvados']
        campa√±a_segmentacion = [1287.81 + 1572.48 + 520.52, 10360 + 24080 + 24080]  # [3380.81, 58520]
        campa√±a_siono = [5740, 23240]

        x = np.arange(len(labels))  # posiciones 0,1
        width = 0.35  # ancho barras

        fig, ax = plt.subplots(figsize=(6, 4))

        # Barras lado a lado
        bars1 = ax.bar(x - width / 2, campa√±a_segmentacion, width, label='Campa√±a Segmentaci√≥n', color='#2980b9')
        bars2 = ax.bar(x + width / 2, campa√±a_siono, width, label='Campa√±a S√≠/No', color='#27ae60')

        # Etiquetas y t√≠tulo
        ax.set_ylabel('EUR', fontsize=10)
        ax.set_xticks(x)
        ax.set_xticklabels(labels, fontsize=9)
        ax.set_title('Comparaci√≥n de Costes e Ingresos entre Campa√±as', fontsize=12)
        ax.legend(fontsize=9)
        ax.tick_params(axis='y', labelsize=8)

        # Funci√≥n para poner anotaciones dentro de las barras
        def annotate_bars(bars):
            for bar in bars:
                height = bar.get_height()
                ax.text(
                    bar.get_x() + bar.get_width() / 2,
                    height / 2,
                    f'{height:,.0f} EUR',
                    ha='center',
                    va='center',
                    color='black',
                    fontsize=8,
                    fontweight='bold'
                )

        annotate_bars(bars1)
        annotate_bars(bars2)

        # L√≠neas que conectan las barras de cada categor√≠a
        for i in range(len(x)):
            # Obtener las coordenadas centrales superiores de cada barra
            x1 = bars1[i].get_x() + bars1[i].get_width() / 2
            y1 = bars1[i].get_height()
            x2 = bars2[i].get_x() + bars2[i].get_width() / 2
            y2 = bars2[i].get_height()
            # Dibujar l√≠nea entre barras
            ax.plot([x1, x2], [y1, y2], 'k--', lw=1)

        st.pyplot(fig)

        st.subheader("Conclusi√≥n de la Comparaci√≥n de Campa√±as")
        st.markdown("""
        La comparaci√≥n visual entre la campa√±a de segmentaci√≥n y la campa√±a tradicional ‚ÄúS√≠/No‚Äù revela diferencias significativas en t√©rminos de coste y beneficio econ√≥mico.

        - **Coste de la campa√±a:** La campa√±a de segmentaci√≥n tiene un coste total considerablemente menor (~3.380 EUR) frente a la campa√±a S√≠/No (~5.740 EUR), lo que indica un uso m√°s eficiente del presupuesto.
          
        - **Ingresos salvados:** Por otro lado, la campa√±a de segmentaci√≥n genera ingresos salvados m√°s altos (~58.520 EUR) en comparaci√≥n con la campa√±a S√≠/No (~23.240 EUR), casi el doble, demostrando una mayor efectividad en retener clientes.

        - **Relaci√≥n coste-beneficio:** Esto se traduce en un retorno de inversi√≥n mucho m√°s favorable para la campa√±a de segmentaci√≥n, lo que sugiere que invertir en estrategias diferenciadas y segmentadas permite optimizar recursos y maximizar resultados.

        En resumen, la campa√±a de segmentaci√≥n es claramente la opci√≥n preferible para maximizar beneficios, reducir gastos y mejorar la eficiencia de las acciones de retenci√≥n de clientes.
        """)

 

elif selected == "Predictor de Churn":
    st.title("Predicci√≥n de Churn con tu CSV")
    st.markdown("Carga un archivo CSV con datos de tus clientes y obt√©n la predicci√≥n de abandono.")

    # Clase para limpieza num√©rica
    class NumericCleaner(BaseEstimator, TransformerMixin):
        def __init__(self, columns):
            self.columns = columns
        def fit(self, X, y=None):
            return self
        def transform(self, X):
            X = X.copy()
            for col in self.columns:
                X[col] = pd.to_numeric(X[col].replace(' ', np.nan), errors='coerce').astype('float64')
            return X

    uploaded_file = st.file_uploader("Carga tu archivo CSV", type="csv")

    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)

            customer_ids = df["customerID"].copy()

            # Columnas a eliminar (coincidir con pipeline)
            cols_drop = [
                'customerID', 'DeviceProtection', 'StreamingTV', 'gender',
                'PhoneService', 'Dependents', 'TechSupport', 'StreamingMovies'
            ]
            df = df.drop(columns=[col for col in cols_drop if col in df.columns])

            # Cargar pipeline pre-entrenado (aseg√∫rate que pipeline_churn.joblib est√° en el mismo directorio)
            pipeline = joblib.load("pipeline_churn.joblib")

            # Predecir probabilidades y clases
            probs = pipeline.predict_proba(df)[:, 1]
            preds = pipeline.predict(df)

            # Mostrar resultados en dataframe
            resultado = pd.DataFrame({
                "customerID": customer_ids,
                "Probabilidad_Churn": probs,
                "Prediccion_Churn": preds
            })

            st.success("‚úÖ Predicci√≥n completada.")
            st.dataframe(resultado)

            # Bot√≥n para descargar resultados
            csv = resultado.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• Descargar resultados como CSV",
                data=csv,
                file_name='predicciones_churn.csv',
                mime='text/csv'
            )

        except Exception as e:
            st.error(f"‚ö†Ô∏è Error al procesar el archivo: {e}")
